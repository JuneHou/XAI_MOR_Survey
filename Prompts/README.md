# Detailed Methodology for Generating Free-Text Rationales

We use in-context learning [(Brown et al., 2020)](https://api.semanticscholar.org/CorpusID:218971783) by including six admission note examples with their ground-truth labels and one test admission note for inference. 
Examples are selected using the kNN-augmented In-Context Example Selection method (KATE) introduced by [Liu et al. (2021a)](https://aclanthology.org/2022.deelio-1.10/). To further mitigate majority bias and recency bias, as discussed in [Zhao et al. (2021)](https://proceedings.mlr.press/v139/zhao21c/zhao21c.pdf), we implement the following when retrieving the six nearest neighbors. To avoid majority label bias, we retrieve the nearest three positive (mortality) and three negative (survived) admission notes. We shuffle the order to present alternating labels (i.e., positive, negative, positive...) to avoid recency bias. Prompting and visualization of the conversation are achieved with the [Guidance toolkit](https://github.com/guidance-ai/guidance). Based on OpenAI recommendations, we use “You are a helpful assistant” as the system message in all tasks. To ensure the answer is consistent, the temperature for all responses is set to 0. 
The prompt we used to generate rationales is shown in [here]().
